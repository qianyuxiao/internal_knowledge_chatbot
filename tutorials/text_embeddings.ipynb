{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e4d03c-094a-4278-815c-fed2dd8d925a",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "- load text\n",
    "- Create embeddings\n",
    "- Save as json in bucket\n",
    "- Create index with above bucket\n",
    "- Create endpoint\n",
    "- Deploy index to endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f89f2f-55ab-46c9-912e-8969c052b417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud-aiplatform google-cloud-storage 'google-cloud-bigquery[pandas]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53cf0251-34a9-4aa4-9436-191053cba087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "# import time\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c5fb3fb-0746-4f9d-83b2-92b6b7b39546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get project ID\n",
    "PROJECT_ID = 'ecg-ai-416210'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e342e227-cd61-456f-bac8-c23d680a4575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCATION = 'europe-west1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349bdab4-c91a-4630-8348-e747687ce3df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Enable APIs\n",
    "\n",
    "Run the following to enable APIs for Compute Engine, Vertex AI, Cloud Storage and BigQuery with this Google Cloud project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a537cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b222dd2b-39b8-47f0-9a4c-1a2a4600fbfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! gcloud services enable compute.googleapis.com aiplatform.googleapis.com storage.googleapis.com bigquery.googleapis.com --project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63b245-c0d3-4956-9f2a-35770590a181",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c11f4efe-8805-4821-8205-3579024044be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64232071</td>\n",
       "      <td>gh-pages script cannot commit .nojekyll to GitHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64276234</td>\n",
       "      <td>WARNING:tensorflow:Can save best model only wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64183423</td>\n",
       "      <td>Cumulative (running) sum of field Django and M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64392487</td>\n",
       "      <td>Add space between cells in RecyclerView?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64285237</td>\n",
       "      <td>Ansbile way of having multiple MAILTO environm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title\n",
       "0  64232071  gh-pages script cannot commit .nojekyll to GitHub\n",
       "1  64276234  WARNING:tensorflow:Can save best model only wi...\n",
       "2  64183423  Cumulative (running) sum of field Django and M...\n",
       "3  64392487           Add space between cells in RecyclerView?\n",
       "4  64285237  Ansbile way of having multiple MAILTO environm..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the BQ Table into a Pandas Dataframe\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "QUESTIONS_SIZE = 1000\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "QUERY_TEMPLATE = \"\"\"\n",
    "        SELECT distinct q.id, q.title\n",
    "        FROM (SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "        where Score > 0 ORDER BY View_Count desc) AS q\n",
    "        LIMIT {limit} ;\n",
    "        \"\"\"\n",
    "query = QUERY_TEMPLATE.format(limit=QUESTIONS_SIZE)\n",
    "query_job = bq_client.query(query)\n",
    "rows = query_job.result()\n",
    "df = rows.to_dataframe()\n",
    "\n",
    "# examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006494a9-f4da-4af2-bc3d-4003ef1d9d1e",
   "metadata": {},
   "source": [
    "## Call the API to generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca4d2d7c-42af-4d41-9b74-6f7c41449fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init the vertexai package\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc60e64e-4daf-4cd9-a923-e51ed263d60f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the text embeddings model\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de820b5a-2ed4-4cc8-81dd-0902a5093143",
   "metadata": {},
   "source": [
    "By default, the text embeddings API has a \"request per minute\" quota set to 60 for new Cloud projects and 600 for projects with usage history (see Quotas and limits to check the latest quota value for base_model:textembedding-gecko). So, rather than using the function directly, you may want to define a wrapper like below to limit under 10 calls per second, and pass 5 texts each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b0bfe65-257d-4dbe-b6e9-eff1a75d0cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm  # to show a progress bar\n",
    "\n",
    "# get embeddings for a list of texts\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "\n",
    "def get_embeddings_wrapper(texts):\n",
    "    embs = []\n",
    "    for i in tqdm.tqdm(range(0, len(texts), BATCH_SIZE)):\n",
    "        time.sleep(1)  # to avoid the quota error\n",
    "        result = model.get_embeddings(texts[i : i + BATCH_SIZE])\n",
    "        embs = embs + [e.values for e in result]\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "add6c6d1-e463-45f0-bb93-34cdd9fe0f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:12<00:00,  1.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64232071</td>\n",
       "      <td>gh-pages script cannot commit .nojekyll to GitHub</td>\n",
       "      <td>[0.014327898621559143, -0.01347998809069395, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64276234</td>\n",
       "      <td>WARNING:tensorflow:Can save best model only wi...</td>\n",
       "      <td>[0.016726359724998474, -0.026153581216931343, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64183423</td>\n",
       "      <td>Cumulative (running) sum of field Django and M...</td>\n",
       "      <td>[-0.025510864332318306, 0.0010844580829143524,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64392487</td>\n",
       "      <td>Add space between cells in RecyclerView?</td>\n",
       "      <td>[-0.016930606216192245, -0.010796603746712208,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64285237</td>\n",
       "      <td>Ansbile way of having multiple MAILTO environm...</td>\n",
       "      <td>[-0.0006941449828445911, -0.017993779852986336...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  64232071  gh-pages script cannot commit .nojekyll to GitHub   \n",
       "1  64276234  WARNING:tensorflow:Can save best model only wi...   \n",
       "2  64183423  Cumulative (running) sum of field Django and M...   \n",
       "3  64392487           Add space between cells in RecyclerView?   \n",
       "4  64285237  Ansbile way of having multiple MAILTO environm...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.014327898621559143, -0.01347998809069395, -...  \n",
       "1  [0.016726359724998474, -0.026153581216931343, ...  \n",
       "2  [-0.025510864332318306, 0.0010844580829143524,...  \n",
       "3  [-0.016930606216192245, -0.010796603746712208,...  \n",
       "4  [-0.0006941449828445911, -0.017993779852986336...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get embeddings for the question titles and add them as \"embedding\" column\n",
    "df = df.assign(embedding=get_embeddings_wrapper(list(df.title)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2d1c67e-7bbe-4c45-8e81-0a921aeb6620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['embedding'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c90c7f7-3d87-4c4f-9322-2dfc79be5d55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['embedding'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863691d1-dade-4df7-a5e5-d8c7e5cc067b",
   "metadata": {},
   "source": [
    "## Save the embeddings in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1c7dcf4-351b-4788-b591-e67a979a480e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save id and embedding as a json file\n",
    "jsonl_string = df[[\"id\", \"embedding\"]].to_json(orient=\"records\", lines=True)\n",
    "with open(\"questions.json\", \"w\") as f:\n",
    "    f.write(jsonl_string)\n",
    "\n",
    "# show the first few lines of the json file\n",
    "# ! head -n 3 questions.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8244e-6a06-48b9-89ca-0aef136af0af",
   "metadata": {},
   "source": [
    "create a new Cloud Storage bucket and copy the file to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "424dd8c3-0ec8-4744-aa8e-a954d7755992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://ecg-ai-416210-text-embeddings/...\n",
      "Copying file://questions.json [Content-Type=application/json]...\n",
      "/ [1 files][  9.8 MiB/  9.8 MiB]                                                \n",
      "Operation completed over 1 objects/9.8 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "BUCKET_URI = f\"gs://{PROJECT_ID}-text-embeddings\"\n",
    "! gsutil mb -l $LOCATION -p {PROJECT_ID} {BUCKET_URI}\n",
    "! gsutil cp questions.json {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb13a5-2e90-4616-9a7f-a44d91a347d9",
   "metadata": {},
   "source": [
    "## Creat an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33e4fbd0-1e5e-43ee-b052-42e57724b969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init the aiplatform package\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0867ca18-7ae2-4271-a51b-f8311d7df74d",
   "metadata": {},
   "source": [
    "#### The parameters for creating index\n",
    "\n",
    "- `contents_delta_uri`: The URI of Cloud Storage directory where you stored the embedding JSON files\n",
    "- `dimensions`: Dimension size of each embedding. In this case, it is 768 as we are using the embeddings from the Text Embeddings API.\n",
    "- `approximate_neighbors_count`: how many similar items we want to retrieve in typical cases\n",
    "- `distance_measure_type`: what metrics to measure distance/similarity between embeddings. In this case it's `DOT_PRODUCT_DISTANCE`\n",
    "\n",
    "See [the document](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index) for more details on creating Index and the parameters.\n",
    "\n",
    "#### Batch Update or Streaming Update?\n",
    "There are two types of index: Index for *Batch Update* (used in this tutorial) and Index for *Streaming Updates*. The Batch Update index can be updated with a batch process whereas the Streaming Update index can be updated in real-time. The latter one is more suited for use cases where you want to add or update each embeddings in the index more often, and crucial to serve with the latest embeddings, such as e-commerce product search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b0b7e-9c17-40a5-bd8e-326920022a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create index\n",
    "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=f\"embvs-tutorial-index\",\n",
    "    contents_delta_uri=BUCKET_URI,\n",
    "    dimensions=768,\n",
    "    approximate_neighbors_count=20,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeb16f9-9481-4004-a25d-3ad15779b8e0",
   "metadata": {},
   "source": [
    "By calling the `create_tree_ah_index` function, it starts building an Index. This will take under a few minutes if the dataset is small, otherwise about 50 minutes or more depending on the size of the dataset. You can check status of the index creation on [the Vector Search Console > INDEXES tab](https://console.cloud.google.com/vertex-ai/matching-engine/indexes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c27c8d-5696-4f5f-a4a1-9bd7ba46a761",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Index Endpoint and deploy the Index\n",
    "\n",
    "To use the Index, you need to create an [Index Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public). It works as a server instance accepting query requests for your Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b051777-922b-48ab-aa2a-c859138c07d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/500033913879/locations/europe-west1/indexEndpoints/3653061412588093440/operations/7651199601751359488\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/500033913879/locations/europe-west1/indexEndpoints/3653061412588093440\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/500033913879/locations/europe-west1/indexEndpoints/3653061412588093440')\n"
     ]
    }
   ],
   "source": [
    "# create IndexEndpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=f\"embvs-tutorial-index-endpoint\",\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26806d-3f60-4603-ad1c-b5e64055db80",
   "metadata": {},
   "source": [
    "This tutorial utilizes a [Public Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/setup/setup#choose-endpoint) and does not support [Virtual Private Cloud (VPC)](https://cloud.google.com/vpc/docs/private-services-access). Unless you have a specific requirement for VPC, we recommend using a Public Endpoint. Despite the term \"public\" in its name, it does not imply open access to the public internet. Rather, it functions like other endpoints in Vertex AI services, which are secured by default through IAM. Without explicit IAM permissions, as we have previously established, no one can access the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45a5e37b-95ef-419f-bf92-5c804b6b7c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = f\"embvs_tutorial_deployed\"\n",
    "# deploy the Index to the Index Endpoint\n",
    "my_index_endpoint.deploy_index(index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c2d4a-64b5-4702-b526-adfc6d199be1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test embedding by query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4847d436-b5f3-45aa-bbe4-f099b5434dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = get_embeddings_wrapper([\"How to read JSON with Python?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87568fd1-286b-4aed-9997-03528f9c3f03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7509 How to partially deserialise a JSON object?\n",
      "0.7172 JSON parse reviver\n",
      "0.6936 Basic request to mongodb with pymongo\n",
      "0.6876 How to know Multiple TLS versions of the host using python?\n",
      "0.6838 How to include OPENJSON in View?\n",
      "0.6805 Not able to join a string properly in python\n",
      "0.6802 How do I pivot this dataframe in Pandas with duplicate keys?\n",
      "0.6796 Is there a way to fix this \"TypeError: express.json is not a function\" when testing Express with Jest?\n",
      "0.6794 How to sort a nested dictionary in Python 2 times?\n",
      "0.6788 How to add JSON request and response examples in Swagger (OpenApi)?\n",
      "0.6781 Why is Pipenv not picking up my Pyenv versions?\n",
      "0.6586 How can I merge a Pandas dataframes based on a substring from one of the columns?\n",
      "0.6564 Python : How can I check if the content of one entire column of a Dataframe is empty?\n",
      "0.6563 How to show json external api in input field in Angular 9?\n",
      "0.6558 Acces array variables from a json file in Unity\n",
      "0.6557 Django: How to filter model objects after passing through functions?\n",
      "0.6532 Python 3.9: unpickling of IsoCalendarDate data returns a tuple\n",
      "0.6527 Based on multiple conditions how to get a sub-group of DataFrame in Python?\n",
      "0.6525 Jackson: deserialize JSON extract deep attribute into parent class\n",
      "0.6519 How to normalize the response API using Normalizr?\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=20,\n",
    ")\n",
    "\n",
    "# show the result\n",
    "import numpy as np\n",
    "\n",
    "for idx, neighbor in enumerate(response[0]):\n",
    "    id = np.int64(neighbor.id)\n",
    "    similar = df.query(\"id == @id\", engine=\"python\")\n",
    "    print(f\"{neighbor.distance:.4f} {similar.title.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87db58-9e35-403e-b568-6829a163a9da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Get an existing Index/Enpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1de7c19-fa7e-4b51-be50-0a6288298a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_index_id = \"3642550081426554880\"  # @param {type:\"string\"}\n",
    "my_index = aiplatform.MatchingEngineIndex(my_index_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6b7bde2-2d37-4e2b-86e1-5b2e4d321fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index.MatchingEngineIndex object at 0x7fc682aa2230> \n",
       "resource name: projects/500033913879/locations/europe-west1/indexes/3642550081426554880"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13e14763-0ec3-4554-8339-a3a8022ef01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_index_endpoint_id = \"7526157092126720000\"  # @param {type:\"string\"}\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(my_index_endpoint_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd232c-ee79-429c-8c21-9af0bae1e6a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e9a2116-0d63-418b-b190-722a4bb49334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://ecg-ai-416210-text-embeddings/questions.json#1711531973811442...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n",
      "Removing gs://ecg-ai-416210-text-embeddings/...\n"
     ]
    }
   ],
   "source": [
    "# wait for a confirmation\n",
    "# input(\"Press Enter to delete Index Endpoint, Index and Cloud Storage bucket:\")\n",
    "\n",
    "# # delete Index Endpoint\n",
    "# my_index_endpoint.undeploy_all()\n",
    "# my_index_endpoint.delete(force=True)\n",
    "\n",
    "# # delete Index\n",
    "# my_index.delete()\n",
    "\n",
    "# delete Cloud Storage bucket\n",
    "! gsutil rm -r {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
