{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef16f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd8be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the directory to sys.path\n",
    "sys.path.append('/home/qianyucazelles/chatbot_rag/src')\n",
    "from utils.doc_to_vertex_search import *\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce3655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def print_with_time(message):\n",
    "    current_time = datetime.now()\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{formatted_time}] {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957205f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_to_list(input_file):\n",
    "    # Initialize an empty list to store the item paths\n",
    "    item_paths = []\n",
    "\n",
    "    # Open the file in read mode\n",
    "    with open(input_file, \"r\") as f:\n",
    "        # Read each line in the file\n",
    "        for line in f:\n",
    "            # Remove trailing whitespace and newline characters\n",
    "            line = line.strip()\n",
    "            # Append the cleaned line to the list\n",
    "            item_paths.append(line)\n",
    "    return item_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6a96952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_with_line(message):\n",
    "    print(\"-\"*100)\n",
    "    print_with_time(message)\n",
    "    \n",
    "def print_with_star(message):\n",
    "    print(\"*\"*100)\n",
    "    print_with_time(message)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5746eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_vector_search(\n",
    "    pdf_path,\n",
    "    me,\n",
    "    unstructure_loader: bool=True,\n",
    "    split_to_article: bool=False\n",
    "):\n",
    "    print_with_time(f\"Process file:{pdf_path} \")\n",
    "    \n",
    "    #load pages\n",
    "    if unstructure_loader:\n",
    "        print(\"Using unstrucure loader\")\n",
    "        loader = UnstructuredPDFLoader(f'{pdf_path}')\n",
    "    else:\n",
    "        loader = PyPDFLoader(f'{pdf_path}')\n",
    "    pages = loader.load()\n",
    "    \n",
    "    print_with_line(f\"len of pages:{len(pages)}\")\n",
    "    \n",
    "    #split to article\n",
    "    if split_to_article:\n",
    "        articles = split_pages_into_artiles(pages)\n",
    "        doc_splits = text_to_chunk(articles)\n",
    "    else:\n",
    "        doc_splits = text_to_chunk(pages)\n",
    "        \n",
    "\n",
    "    print_with_line(f\"n splits:{len(doc_splits)}\")\n",
    "    \n",
    "    #add to vector store\n",
    "    doc_ids = add_splits_to_vector_store(doc_splits,me)\n",
    "    \n",
    "    \n",
    "    if len(doc_ids)>0:\n",
    "        \n",
    "        print_with_line(f\"Added to vector store with {len(doc_ids)} ids.\")\n",
    "        \n",
    "        with open(\"../add_docs_to_vectorstore_logs/processed_pdfs.txt\", \"a\") as f:\n",
    "            f.write(f\"'{pdf_path}',\\n\")\n",
    "        with open(\"../add_docs_to_vectorstore_logs/processed_pdfs_doc_ids.txt\", \"a\") as f:\n",
    "            f.write(f\"'{pdf_path}': {doc_ids},\\n\")\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print_with_star(\"No doc ids returned\")\n",
    "        \n",
    "        with open(f\"../add_docs_to_vectorstore_logs/unprocessed_pdfs.txt\", \"a\") as f:\n",
    "            f.write(f\"'{pdf_path}',\" + \"\\n\")\n",
    "            \n",
    "    return doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b54c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(me,CHATBOT_ID, folder_path, pdf_doc_ids, other_files):\n",
    "    processed_pdfs = read_txt_to_list(\"../add_docs_to_vectorstore_logs/processed_pdfs.txt\")     \n",
    "    for item in os.listdir(folder_path):\n",
    "        \n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        print_with_time(f\"Scanning {item_path}\")\n",
    "        \n",
    "        if os.path.isdir(item_path):\n",
    "            \n",
    "            print_with_time(f\"{item_path} is folder, now go to new level\")\n",
    "            process_folder(me,CHATBOT_ID,item_path,pdf_doc_ids, other_files)\n",
    "            \n",
    "        elif item.lower().endswith('.pdf'):\n",
    "            if item not in processed_pdfs:\n",
    "                \n",
    "                print_with_time(f\"{item_path} is pdf, now process to vector store\")\n",
    "                try:\n",
    "                    \n",
    "                    doc_ids = pdf_to_vector_search(item_path,me)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    with open(f\"../add_docs_to_vectorstore_logs/unprocessed_pdfs.txt\", \"a\") as f:\n",
    "                        f.write(f\"'{item_path}',\" + \"\\n\")\n",
    "                    print(f\"An error occurred while processing {item_path}: {e}\")\n",
    "                    doc_ids=[]\n",
    "                pdf_doc_ids[item_path]=doc_ids\n",
    "            \n",
    "        else:\n",
    "            other_files.append(item_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea086f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(me,\n",
    "         CHATBOT_ID: str,\n",
    "         root_folder: str\n",
    "         ):\n",
    "    \n",
    "    pdf_data = {}\n",
    "    other_files = []\n",
    "    \n",
    "    process_folder(me,CHATBOT_ID,root_folder, pdf_data, other_files)\n",
    "    \n",
    "    # Writing PDF data to JSON file\n",
    "    pdf_output_file = f\"../add_docs_to_vectorstore_logs/{CHATBOT_ID}_pdf_doc_ids.json\"\n",
    "    with open(pdf_output_file, \"w\") as json_file:\n",
    "        json.dump(pdf_data, json_file, indent=4)\n",
    "    print(f\"PDF data has been written to {pdf_output_file}\")\n",
    "    \n",
    "    # Writing other files list to JSON file\n",
    "    other_output_file = f\"../add_docs_to_vectorstore_logs/{CHATBOT_ID}_non_pdf_files.json\"\n",
    "    with open(other_output_file, \"w\") as json_file:\n",
    "        json.dump(other_files, json_file, indent=4)\n",
    "    print(f\"Non-PDF files list has been written to {other_output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b2a8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp gs://ecg_assurance/me_parameters/ecg_assurance_me.json ../vector_store_me_parameters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed4277e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 20:15:28.323942: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-17 20:15:33] Scanning ../documents/ecg_assurance/Contrats 2024\n",
      "[2024-04-17 20:15:33] ../documents/ecg_assurance/Contrats 2024 is folder, now go to new level\n",
      "[2024-04-17 20:15:33] Scanning ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE\n",
      "[2024-04-17 20:15:33] ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE is folder, now go to new level\n",
      "[2024-04-17 20:15:33] Scanning ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/NEW Contratto polizza magazzino Manerba.pdf\n",
      "[2024-04-17 20:15:33] ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/NEW Contratto polizza magazzino Manerba.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:15:33] Process file:../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/NEW Contratto polizza magazzino Manerba.pdf \n",
      "Using unstrucure loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qianyucazelles/internal_knowledge_chatbot/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:16:11] len of pages:len(pages)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:16:11] n splits:len(doc_splits)\n",
      "Waiting\n",
      "...successfully added to vector store with 19 new doc ids\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:16:16] Added to vector store with 19 ids.\n",
      "[2024-04-17 20:16:16] Scanning ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant police LOCAUX DE STOCKAGE Allianz 2024.pdf\n",
      "[2024-04-17 20:16:16] ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant police LOCAUX DE STOCKAGE Allianz 2024.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:16:16] Process file:../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant police LOCAUX DE STOCKAGE Allianz 2024.pdf \n",
      "Using unstrucure loader\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:17:54] len of pages:len(pages)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:17:54] n splits:len(doc_splits)\n",
      "Waiting\n",
      ".......successfully added to vector store with 39 new doc ids\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:02] Added to vector store with 39 ids.\n",
      "[2024-04-17 20:18:02] Scanning ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant police LOCAUX DE STOCKAGE LPS Allianz 2024.pdf\n",
      "[2024-04-17 20:18:02] ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant police LOCAUX DE STOCKAGE LPS Allianz 2024.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:18:02] Process file:../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant police LOCAUX DE STOCKAGE LPS Allianz 2024.pdf \n",
      "Using unstrucure loader\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:18] len of pages:len(pages)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:18] n splits:len(doc_splits)\n",
      "Waiting\n",
      ".successfully added to vector store with 9 new doc ids\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:20] Added to vector store with 9 ids.\n",
      "[2024-04-17 20:18:20] Scanning ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant 2024 Police locaux de stockage Allianz.pdf\n",
      "[2024-04-17 20:18:20] ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant 2024 Police locaux de stockage Allianz.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:18:20] Process file:../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant 2024 Police locaux de stockage Allianz.pdf \n",
      "Using unstrucure loader\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:23] len of pages:len(pages)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:23] n splits:len(doc_splits)\n",
      "Waiting\n",
      "........successfully added to vector store with 41 new doc ids\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:31] Added to vector store with 41 ids.\n",
      "[2024-04-17 20:18:31] Scanning ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant LPS 2024 police locaux de stockage Allianz.pdf\n",
      "[2024-04-17 20:18:31] ../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant LPS 2024 police locaux de stockage Allianz.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:18:31] Process file:../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/Avenant LPS 2024 police locaux de stockage Allianz.pdf \n",
      "Using unstrucure loader\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:32] len of pages:len(pages)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:32] n splits:len(doc_splits)\n",
      "Waiting\n",
      ".successfully added to vector store with 7 new doc ids\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:33] Added to vector store with 7 ids.\n",
      "[2024-04-17 20:18:33] Scanning ../documents/ecg_assurance/Contrats 2024/ECG ITALIA - véhicules\n",
      "[2024-04-17 20:18:33] ../documents/ecg_assurance/Contrats 2024/ECG ITALIA - véhicules is folder, now go to new level\n",
      "[2024-04-17 20:18:33] Scanning ../documents/ecg_assurance/Contrats 2024/ECG ITALIA - véhicules/polizza ECG Italia Srl n. 533662573 _ copia per direzione firmata.pdf\n",
      "[2024-04-17 20:18:33] ../documents/ecg_assurance/Contrats 2024/ECG ITALIA - véhicules/polizza ECG Italia Srl n. 533662573 _ copia per direzione firmata.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:18:33] Process file:../documents/ecg_assurance/Contrats 2024/ECG ITALIA - véhicules/polizza ECG Italia Srl n. 533662573 _ copia per direzione firmata.pdf \n",
      "Using unstrucure loader\n",
      "An error occurred while processing ../documents/ecg_assurance/Contrats 2024/ECG ITALIA - véhicules/polizza ECG Italia Srl n. 533662573 _ copia per direzione firmata.pdf: Unable to get page count.\n",
      "Syntax Error: Gen inside xref table too large (bigger than INT_MAX)\n",
      "Syntax Error: Couldn't find trailer dictionary\n",
      "Syntax Error: Gen inside xref table too large (bigger than INT_MAX)\n",
      "Syntax Error: Couldn't find trailer dictionary\n",
      "Syntax Error: Couldn't read xref table\n",
      "\n",
      "[2024-04-17 20:18:45] Scanning ../documents/ecg_assurance/Contrats 2024/RCMS\n",
      "[2024-04-17 20:18:45] ../documents/ecg_assurance/Contrats 2024/RCMS is folder, now go to new level\n",
      "[2024-04-17 20:18:45] Scanning ../documents/ecg_assurance/Contrats 2024/RCMS/CI10476799 ECG TOPCO - Attestation 2023.pdf\n",
      "[2024-04-17 20:18:45] ../documents/ecg_assurance/Contrats 2024/RCMS/CI10476799 ECG TOPCO - Attestation 2023.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:18:45] Process file:../documents/ecg_assurance/Contrats 2024/RCMS/CI10476799 ECG TOPCO - Attestation 2023.pdf \n",
      "Using unstrucure loader\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:45] len of pages:len(pages)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:45] n splits:len(doc_splits)\n",
      "Waiting\n",
      "successfully added to vector store with 3 new doc ids\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:46] Added to vector store with 3 ids.\n",
      "[2024-04-17 20:18:46] Scanning ../documents/ecg_assurance/Contrats 2024/RCMS/POLICE RCMS SIGNEE 2023 2024.pdf\n",
      "[2024-04-17 20:18:46] ../documents/ecg_assurance/Contrats 2024/RCMS/POLICE RCMS SIGNEE 2023 2024.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:18:46] Process file:../documents/ecg_assurance/Contrats 2024/RCMS/POLICE RCMS SIGNEE 2023 2024.pdf \n",
      "Using unstrucure loader\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:52] len of pages:len(pages)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:52] n splits:len(doc_splits)\n",
      "Waiting\n",
      "successfully added to vector store with 3 new doc ids\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:53] Added to vector store with 3 ids.\n",
      "[2024-04-17 20:18:53] Scanning ../documents/ecg_assurance/Contrats 2024/RCMS/CI 10476799 ECG TOPCO - Avenant 1.pdf\n",
      "[2024-04-17 20:18:53] ../documents/ecg_assurance/Contrats 2024/RCMS/CI 10476799 ECG TOPCO - Avenant 1.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:18:53] Process file:../documents/ecg_assurance/Contrats 2024/RCMS/CI 10476799 ECG TOPCO - Avenant 1.pdf \n",
      "Using unstrucure loader\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:53] len of pages:len(pages)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:53] n splits:len(doc_splits)\n",
      "Waiting\n",
      "successfully added to vector store with 3 new doc ids\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2024-04-17 20:18:54] Added to vector store with 3 ids.\n",
      "[2024-04-17 20:18:54] Scanning ../documents/ecg_assurance/Contrats 2024/AUTO\n",
      "[2024-04-17 20:18:54] ../documents/ecg_assurance/Contrats 2024/AUTO is folder, now go to new level\n",
      "[2024-04-17 20:18:54] Scanning ../documents/ecg_assurance/Contrats 2024/AUTO/Allianz local pour Arinella Bianca\n",
      "[2024-04-17 20:18:54] ../documents/ecg_assurance/Contrats 2024/AUTO/Allianz local pour Arinella Bianca is folder, now go to new level\n",
      "[2024-04-17 20:18:54] Scanning ../documents/ecg_assurance/Contrats 2024/AUTO/Allianz local pour Arinella Bianca/ALLIANZ 2023 Cotisations tous les contrats + 1 nouveau + 2 résiliés en 2023.pdf\n",
      "[2024-04-17 20:18:54] ../documents/ecg_assurance/Contrats 2024/AUTO/Allianz local pour Arinella Bianca/ALLIANZ 2023 Cotisations tous les contrats + 1 nouveau + 2 résiliés en 2023.pdf is pdf, now process to vector store\n",
      "[2024-04-17 20:18:54] Process file:../documents/ecg_assurance/Contrats 2024/AUTO/Allianz local pour Arinella Bianca/ALLIANZ 2023 Cotisations tous les contrats + 1 nouveau + 2 résiliés en 2023.pdf \n",
      "Using unstrucure loader\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    CHATBOT_ID = \"ecg_assurance\"\n",
    "    root_folder = f\"../documents/{CHATBOT_ID}/\"\n",
    "    # get embeddings\n",
    "    embeddings = get_embeddings()\n",
    "\n",
    "    #get parameters\n",
    "    parameters = get_me_parameters(f'../vector_store_me_parameters/{CHATBOT_ID}_me.json')\n",
    "\n",
    "    #get vector store\n",
    "    me = get_vector_store(parameters, embeddings)\n",
    "    \n",
    "    main(me,CHATBOT_ID,root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_path = \"/home/qianyucazelles/internal_knowledge_chatbot/src/documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/NEW Contratto polizza magazzino Manerba.pdf\",\"ecg_assurance\"\n",
    "# CHATBOT_ID = \"ecg_assurance\"\n",
    "# root_folder = f\"/home/qianyucazelles/chatbot_rag/src/documents/{CHATBOT_ID}/\"\n",
    "# # get embeddings\n",
    "# embeddings = get_embeddings()\n",
    "\n",
    "# #get parameters\n",
    "# parameters = get_me_parameters(f'../vector_store_me_parameters/{CHATBOT_ID}_me.json')\n",
    "\n",
    "# #get vector store\n",
    "# me = get_vector_store(parameters, embeddings)\n",
    "# # pdf_to_vector_search(pdf_path,me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ad7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_to_vector_search(\"../documents/ecg_assurance/Contrats 2024/SIEGES/Generali - Si\\u00e8ge Montpellier.pdf\",me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc936673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = UnstructuredPDFLoader(\"../documents/ecg_assurance/Contrats 2024/LOCAUX DE STOCKAGE/NEW Contratto polizza magazzino Manerba.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee745606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #split to article\n",
    "# split_to_article= False\n",
    "# if split_to_article:\n",
    "#     articles = split_pages_into_artiles(pages)\n",
    "#     doc_splits = text_to_chunk(articles)\n",
    "# else:\n",
    "#     doc_splits = text_to_chunk(pages)\n",
    "    \n",
    "\n",
    "\n",
    "# #add to vector store\n",
    "# doc_ids = add_splits_to_vector_store(doc_splits,me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = get_me_parameters(f'../vector_store_me_parameters/{CHATBOT_ID}_me.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # init the aiplatform package\n",
    "# from google.cloud import aiplatform\n",
    "\n",
    "# aiplatform.init(project=parameters['PROJECT_ID'], location=parameters['LOCATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb714dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(parameters['ME_INDEX_ENDPOINT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a11c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_index_endpoint.undeploy_all()\n",
    "# my_index_endpoint.delete(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ef5e6-0ff4-43b8-ae53-c867bcd6145d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# me.similarity_search(\"way to reserve a booking\", k=4)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
