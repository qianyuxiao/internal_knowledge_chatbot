{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a522b955-ee68-4522-8177-15035d59b09d",
   "metadata": {},
   "source": [
    "# Get Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad56f00-b908-4dbb-ac5a-518d8ef36984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the directory to sys.path\n",
    "sys.path.append('/home/qianyucazelles/internal_knowledge_chatbot/src/utils')\n",
    "from doc_to_vertex_search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80b01fa-b7ff-42d9-83c9-aa2e4a765c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = get_me_parameters('../vector_store_me_parameters/ecg_all_me.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1e33ee-622e-4a76-bb44-bcf0ff1da961",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e211639c-e954-41f2-80c8-1194bee57552",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = get_vector_store(parameters, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f7e621-29b1-4691-96fb-4eaec134e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import (\n",
    "    Namespace,\n",
    "    NumericNamespace,\n",
    ")\n",
    "filters = [Namespace(name=\"department\", allow_tokens=[\"dpo\"]),\n",
    "           Namespace(name=\"loader_method\", allow_tokens=[\"unstructured\"])\n",
    "          ]\n",
    "\n",
    "\n",
    "numeric_filters = [NumericNamespace(name=\"chunk_size\", value_float=2000.0, op=\"EQUAL\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e741dbdf-7f80-4f2d-996b-aa51bf9ddf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b528dbf8-c72a-4c89-83e6-bf8dc9d6faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.search_kwargs = {\"filter\": filters, \"numeric_filter\": numeric_filters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9b19fd0-31eb-42c6-a2f5-10c02111416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Je n'aurai pas le temps de traiter la demande de droit à l'oubli d'un utilisateur dans le mois règlementaire imposé par la CNIL. Ai-je un recours ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd9bffd-71b0-45c2-8a3d-0a21479216eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = \"J'ai des difficultés à comprendre les différentes obligations que j'ai vis-à-vis des sous-traitants qui travaillent pour moi. Pourrais-tu me faire un résumé ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2730bea8-2b5d-476b-bb4f-01fe622b944a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retrieved_documents \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(q)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78e9b375-e1f4-402c-8abd-9e406e426681",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = retriever.invoke(q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5cb06a",
   "metadata": {},
   "source": [
    "## local llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "535fbba8-5189-4dc5-9a4e-23ae13193664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/blog/not-lain/rag-chatbot-using-llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c7e53b9-6cc2-4414-9972-2dc6f6e77fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qianyucazelles/internal_knowledge_chatbot/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:08<00:02,  2.68s/it]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fe592f79630>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/qianyucazelles/internal_knowledge_chatbot/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# use quantization to lower GPU usage\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8edd48f-f05f-4a37-8591-8012aaf3810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e16ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"You are an assistant for answering questions.\n",
    "You are given the extracted parts of several documents rank by relevance with document name and a question. Please pick the most relevant document related to the question then \n",
    "provide a conversational answer in the same language as the question. Always cite the referred document in your response.\n",
    "If you don't know the answer, just say \"I do not know.\" Don't make up an answer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "356db936-5000-4b06-aff1-982cf739cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(prompt,retrieved_documents):\n",
    "  \"\"\"using the retrieved documents we will prompt the model to generate our responses\"\"\"\n",
    "  formatted_prompt = f\"Question:{prompt}\\nContext: \\n\"\n",
    "  separated_line = \"-\"*50+\"\\n\"\n",
    "  for idx,doc in enumerate(retrieved_documents) :\n",
    "    formatted_prompt+= f\"{separated_line} Ranked Document: {idx+1} \\nName: {doc.metadata['document_name']}\\nContent: {doc.page_content} \\n\"\n",
    "  return formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91e11636-9a23-4a60-b3f3-b678a0aef406",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_prompt = format_prompt(q2,retrieved_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "247e5e05-b7db-4156-ab56-2c28f78ea599",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\":\"system\",\"content\":SYS_PROMPT},{\"role\":\"user\",\"content\":formatted_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5d6eba8-2323-4a7a-b2f5-9922b7431f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextIteratorStreamer\n",
    "\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69d38a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_top_p = 0.75\n",
    "llm_top_k = 20\n",
    "llm_temperature = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb9e3e84-fd3e-452a-9adc-18122ddb2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "2024-05-20 18:18:52.495934: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# set streamer\n",
    "streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# apply chat template\n",
    "messages_tmpl = tokenizer.apply_chat_template(messages,\n",
    "                       tokenize=False,\n",
    "                       add_generation_prompt=True\n",
    "                      )\n",
    "\n",
    "# tokenize msgs\n",
    "inputs = tokenizer([messages_tmpl], return_tensors=\"pt\").to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60abc651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Run the generation in a separate thread, so that we can fetch the generated text in a non-blocking way.\n",
    "generation_kwargs = dict(inputs, \n",
    "                         streamer=streamer, \n",
    "                         max_new_tokens=1500,\n",
    "                         eos_token_id=terminators,\n",
    "                         top_k= llm_top_k,\n",
    "                         top_p= llm_top_p,\n",
    "                        do_sample=True,\n",
    "                        temperature=llm_temperature,\n",
    "                         )\n",
    "# chat\n",
    "thread = Thread(target=model.generate,\n",
    "                kwargs=generation_kwargs)\n",
    "thread.start() \n",
    "\n",
    "generated_text = ''\n",
    "for _, new_text in enumerate(streamer):\n",
    "    generated_text += new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdb74f34-c070-4252-bbcc-aff05dd6a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour! Je suis là pour vous aider.\n",
      "\n",
      "En ce qui concerne vos difficultés à comprendre les obligations que vous avez envers les sous-traitants qui travaillent pour vous, je vais vous donner un résumé basé sur le document le plus pertinent, qui est le CHAPITRE IV - Responsable du traitement et sous-traitant du CNIL.\n",
      "\n",
      "Selon ce document, en tant que responsable du traitement, vous devez vous assurer que les sous-traitants que vous embauchent présentent des garanties suffisantes pour mettre en œuvre des mesures techniques et organisationnelles appropriées pour protéger les données personnelles. Vous devez également vous assurer que les sous-traitants ont des obligations claires et précises pour protéger les données personnelles, notamment :\n",
      "\n",
      "* Informer immédiatement le responsable du traitement si une instruction constitue une violation du règlement ou d'autres dispositions du droit de l'Union ou du droit des États membres relatives à la protection des données.\n",
      "* Présenter des garanties suffisantes quant à la mise en œuvre de mesures techniques et organisationnelles appropriées pour protéger les données personnelles.\n",
      "* Veiller à ce que les personnes autorisées à traiter les données personnelles s'engagent à respecter la confidentialité ou soient soumises à une obligation légale appropriée de confidentialité.\n",
      "* Prendre toutes les mesures requises pour protéger les données personnelles, notamment en veillant à ce que les transferts de données à caractère personnel vers un pays tiers ou une organisation internationale soient effectués de manière légale et transparente.\n",
      "\n",
      "En résumé, il est important que vous soyez informé des obligations que les sous-traitants doivent respecter pour protéger les données personnelles et que vous puissiez vous assurer que les sous-traitants ont des garanties suffisantes pour protéger ces données.\n",
      "\n",
      "Source : CHAPITRE IV - Responsable du traitement et sous-traitant du CNIL.\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60302e28-efd5-4fed-8fbb-613f955730f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour! Je suis là pour vous aider.\n",
      "\n",
      "Selon le document le plus pertinent, le CHAPITRE IV - Responsable du traitement et sous-traitant _ CNIL.pdf, il est important de noter que les sous-traitants doivent présenter des garanties suffisantes quant à la mise en œuvre de mesures techniques et organisationnelles appropriées pour protéger les données des personnes concernées.\n",
      "\n",
      "En ce qui concerne vos obligations envers les sous-traitants, vous devez notamment :\n",
      "\n",
      "* Informer immédiatement le sous-traitant si, selon vous, une instruction constitue une violation du règlement ou d'autres dispositions du droit de l'Union ou du droit des États membres relatives à la protection des données.\n",
      "* Imposer des obligations de protection des données à tout autre sous-traitant recruté pour mener des activités de traitement spécifiques pour votre compte.\n",
      "* Veiller à ce que les sous-traitants qui traitent des données à votre place soient soumis à des garanties suffisantes quant à la mise en œuvre de mesures techniques et organisationnelles appropriées.\n",
      "\n",
      "Il est également important de noter que vous devez établir un contrat ou un autre acte juridique avec les sous-traitants pour définir les termes et les conditions du traitement des données à caractère personnel.\n",
      "\n",
      "J'espère que cela vous aidera à mieux comprendre vos obligations envers les sous-traitants. Si vous avez d'autres questions, n'hésitez pas à me demander!\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
